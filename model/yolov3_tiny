import numpy as np
import tensorflow as tf

from tf.keras.layers import (
    Conv2D,
    Concatenate,
    UpSampling2D,
    MaxPooling2D,
    BatchNormalization,
    LeakyReLU,
)


class YOLO_Head(tf.keras.Layer):
    """
    Implements the YOLOv3 head.
    """

    # 2 values for box center offsets(in x an y, relative to cell center),
    # 2 values box size scales (in x and y, relative to anchor dimensions),
    # 1 value for objectness score (between 0 and 1),
    # number-of-classes values for class score (between 0 and 1).

    def __init__(self, anchors, num_classes, img_size, **kwargs):

        super(YOLO_Head, self).__init__(**kwargs)

        self.anchors = anchors
        self.n_anchors = len(self.anchors)
        self.num_classes = num_classes
        self.img_size = img_size

    def call(self, inputs, input_shape):
        """Reshapes `inputs` into final YOLO output format:

        # 2 values for box center offsets(in x an y, relative to cell center),
        # 2 values box size scales (in x and y, relative to anchor dimensions),
        # 1 value for objectness score (between 0 and 1),
        # number-of-classes values for class score (between 0 and 1).
        """

        # 1. Reshape to batch_size x grid_x x grid_y x num_anchors x 5

        grid_y, grid_x = tf.shape(inputs)[1:3]
        n_anchors = self.n_anchors

        inputs = tf.reshape(
            inputs, (-1, grid_y, grid_x, n_anchors, 5 + self.num_classes)
        )

        # 2. Split to batch_size x grid_size x grid_size x num_anchors x 2

        grid_ys = tf.tile(tf.expand_dims(tf.range(grid_y), axis=1), [1, grid_x])
        grid_xs = tf.tile(tf.expand_dims(tf.range(grid_x), axis=0), [grid_y, 1])
        grid = tf.concat(
            [
                grid_xs[:, :, tf.newaxis, tf.newaxis],
                grid_ys[:, :, tf.newaxis, tf.newaxis],
            ],
            axis=-1,
        )
        grid = tf.cast(grid, tf.float32)

        # 3. Add center offset and scale with anchors
        box_xy = (tf.math.sigmoid(inputs[..., :2]) + grid) / tf.cast(
            [grid_y, grid_x], tf.float32
        )
        box_wh = (
            tf.math.exp(inputs[..., 2:4])
            * self.anchors
            / tf.cast(input_shape, tf.float32)
        )
        box_confidence = tf.math.sigmoid(inputs[..., 4:5])
        box_class_probs = tf.math.sigmoid(inputs[..., 5:])

        return box_xy, box_wh, box_confidence, box_class_probs


class ConvUnit(tf.keras.Layer):
    def __init__(
        self,
        filters,
        kernel_size,
        name,
        strides=1,
        padding="SAME",
        activation=None,
        use_bias=False,
        pool=True,
        pool_size=2,
        pool_strides=2,
        **kwargs
    ):
        super(ConvUnit, self).__init__(name=name)
        self.pool = pool
        self.conv = Conv2D(
            filters,
            kernel_size,
            strides=strides,
            padding=padding,
            activation=LeakyReLU(alpha=0.1) if activation is None else activation,
            use_bias=use_bias,
            **kwargs
        )
        self.bn = BatchNormalization()
        if self.pool:
            self.max_pool = MaxPooling2D(pool_size, pool_strides, padding=padding)

    def call(self, inputs):
        x = self.conv(inputs)
        x = self.bn(x)
        if self.pool:
            x = self.max_pool(x)
        return x


class YOLOv3_Tiny(tf.keras.Model):
    def __init__(
        self,
        n_classes,
        n_anchors,
        model_size,
        max_output_size,
        iou_threshold,
        score_threshold,
    ):
        super(YOLOv3_Tiny, self).__init__()
        self.n_classes = n_classes
        self.n_anchors = n_anchors
        self.model_size = model_size
        self.max_output_size = max_output_size
        self.iou_threshold = iou_threshold
        self.score_threshold = score_threshold

        self.conv1 = ConvUnit(16, 3, "conv1")
        self.conv2 = ConvUnit(32, 3, "conv2")
        self.conv3 = ConvUnit(64, 3, "conv3")
        self.conv4 = ConvUnit(128, 3, "conv4")
        self.conv5 = ConvUnit(256, 3, "conv5")
        self.conv6 = ConvUnit(512, 3, "conv6", pool_strides=1)
        self.conv7 = ConvUnit(1024, 3, "conv7", pool=False)

        ######

        self.conv8 = ConvUnit(256, 1, "conv8", pool=False)
        self.conv9 = ConvUnit(512, 3, "conv9", pool=False)
        self.conv10 = ConvUnit(
            self.n_anchors / 2 * (5 + self.num_classes),
            1,
            "conv10",
            pool=False,
            activation="linear",
        )

        ######
        self.concat = Concatenate(axis=-1)

        ### TODO: Insert first YOLO_Head here

        self.conv11 = ConvUnit(128, 1, "conv11", pool=False)
        self.upsample1 = UpSampling2D(2)

        self.conv12 = ConvUnit(256, 3, "conv12", pool=False)
        self.conv13 = ConvUnit(
            self.n_anchors / 2 * (5 + self.num_classes),
            1,
            "conv13",
            activation="linear",
            pool=False,
        )

        ######

        ### TODO: Insert second YOLO_Head here

    def __call__(self, inputs):

        x1 = self.conv1(inputs)
        x1 = self.conv2(x1)
        x1 = self.conv3(x1)
        x1 = self.conv4(x1)
        x1 = self.conv5(x1)

        x2 = self.conv6(x1)
        x2 = self.conv7(x2)
        x2 = self.conv8(x2)

        y1 = self.conv9(x2)
        y1 = self.conv10(y1)

        ######

        x2 = self.conv11(x2)
        x2 = self.upsample1(x2)

        x3 = self.concat([x2, x1])
        y2 = self.conv12(x3)
        y2 = self.conv13(y2)

        ######

        return y1, y2


def yolo_loss(args, anchors):
    # calculate the four different loss functions, then concatenate
    # we are using 2 yolo heads - tiny model specifications

    num_layers = len(anchors)//2
    yolo_outputs = args[:num_layers]
    

def yolo_loss(anchors):
    '''Return yolo_loss tensor
    Parameters
    ----------
    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body
    y_true: list of array, the output of preprocess_true_boxes
    anchors: array, shape=(N, 2), wh
    num_classes: integer
    ignore_thresh: float, the iou threshold whether to ignore object confidence loss
    Returns
    -------
    loss: tensor, shape=(1,)
    '''
    num_layers = len(anchors)//2 # default setting
    yolo_outputs = args[:num_layers]
    y_true = args[num_layers:]
    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]
    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * 32, K.dtype(y_true[0]))
    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]
    loss = 0
    m = K.shape(yolo_outputs[0])[0] # batch size, tensor
    mf = K.cast(m, K.dtype(yolo_outputs[0]))

    for l in range(num_layers):
        object_mask = y_true[l][..., 4:5]
        true_class_probs = y_true[l][..., 5:]

        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],
             anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)
        pred_box = K.concatenate([pred_xy, pred_wh])

        # Darknet raw box to calculate loss.
        raw_true_xy = y_true[l][..., :2]*grid_shapes[l][::-1] - grid
        raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])
        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh)) # avoid log(0)=-inf
        box_loss_scale = 2 - y_true[l][...,2:3]*y_true[l][...,3:4]

        # Find ignore mask, iterate over each of batch.
        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)
        object_mask_bool = K.cast(object_mask, 'bool')
        def loop_body(b, ignore_mask):
            true_box = tf.boolean_mask(y_true[l][b,...,0:4], object_mask_bool[b,...,0])
            iou = box_iou(pred_box[b], true_box)
            best_iou = K.max(iou, axis=-1)
            ignore_mask = ignore_mask.write(b, K.cast(best_iou<ignore_thresh, K.dtype(true_box)))
            return b+1, ignore_mask
        _, ignore_mask = K.control_flow_ops.while_loop(lambda b,*args: b<m, loop_body, [0, ignore_mask])
        ignore_mask = ignore_mask.stack()
        ignore_mask = K.expand_dims(ignore_mask, -1)

        # K.binary_crossentropy is helpful to avoid exp overflow.
        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)
        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh-raw_pred[...,2:4])
        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True)+ \
            (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask
        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)

        xy_loss = K.sum(xy_loss) / mf
        wh_loss = K.sum(wh_loss) / mf
        confidence_loss = K.sum(confidence_loss) / mf
        class_loss = K.sum(class_loss) / mf
        loss += xy_loss + wh_loss + confidence_loss + class_loss
        if print_loss:
            loss = tf.Print(loss, [loss, xy_loss, wh_loss, confidence_loss, class_loss, K.sum(ignore_mask)], message='loss: ')
    return loss
